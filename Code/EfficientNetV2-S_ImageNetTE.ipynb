{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08adb945",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.io import read_image\n",
    "\n",
    "import time\n",
    "import copy\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "class train_stages():\n",
    "    def __init__(self, general_params, stage_params, logger=None) -> None:\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.general_params = general_params\n",
    "        self.stage_params = stage_params\n",
    "        self.logger = logger # in case a ClearML logger can be used\n",
    "\n",
    "    def stage_params_func(self, stage_params, num_stages=4):\n",
    "        # all parameters are linearly scaled with the number of stages\n",
    "        stage = self.stage\n",
    "        num_stages = num_stages-1\n",
    "        \n",
    "        image_size = stage_params[\"image_size_min\"] + ((stage_params[\"image_size_max\"]-stage_params[\"image_size_min\"])/num_stages)*stage # min + (((max - min) / num_stages) * stage)\n",
    "        dropout = stage_params[\"dropout_min\"] + ((stage_params[\"dropout_max\"]-stage_params[\"dropout_min\"])/num_stages)*stage \n",
    "        randaug = stage_params[\"randaug_magnitude_min\"]+ ((stage_params[\"randaug_magnitude_max\"]-stage_params[\"randaug_magnitude_min\"])/num_stages)*stage\n",
    "        self.params = {\n",
    "            \"epochs\": stage_params[\"epochs\"],\n",
    "            \"image_size\": int(image_size),\n",
    "            \"dropout\": dropout,   \n",
    "            \"randaug_magnitude\": int(randaug),\n",
    "        }\n",
    "\n",
    "        print(f\"Parameters for the current stage: \\n{self.params}\")\n",
    "\n",
    "    def data_loader(self):\n",
    "        data_transforms = {\n",
    "            'training': transforms.Compose([\n",
    "                transforms.Resize((self.params[\"image_size\"], self.params[\"image_size\"])),\n",
    "                transforms.RandAugment(magnitude=self.params[\"randaug_magnitude\"]),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            ]),\n",
    "            'validation': transforms.Compose([\n",
    "                transforms.Resize((self.params[\"image_size\"], self.params[\"image_size\"])),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            ]),\n",
    "        }\n",
    "\n",
    "        data_dir = '/Workdir/Data/imagenette2'\n",
    "        image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['training', 'validation']}\n",
    "        self.dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=self.general_params[\"batch_size\"], shuffle=True, num_workers=8) for x in ['training', 'validation']}\n",
    "        self.dataset_sizes = {x: len(image_datasets[x]) for x in ['training', 'validation']}\n",
    "        self.class_names = [\"tench\", \"English springer\", \"cassette player\", \"chain saw\", \"church\", \"French horn\", \"garbage truck\", \"gas pump\", \"golf ball\", \"parachute\"]\n",
    "\n",
    "    def train_model(self, model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "        since = time.time()\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "            print('-' * 10)\n",
    "\n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in ['training', 'validation']:\n",
    "                if phase == 'training':\n",
    "                    model.train()  # Set model to training mode\n",
    "                else:\n",
    "                    model.eval()   # Set model to evaluate mode\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "                \n",
    "                # Iterate over data.\n",
    "                for inputs, labels in self.dataloaders[phase]:\n",
    "                    inputs = inputs.to(self.device)\n",
    "                    labels = labels.to(self.device)\n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                    with torch.set_grad_enabled(phase == 'training'):\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                        # backward + optimize only if in training phase\n",
    "                        if phase == 'training':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    # statistics\n",
    "                    running_loss += loss.item() * inputs.size(0)\n",
    "                    running_corrects += torch.sum(preds == labels.data)\n",
    "                if phase == 'training':\n",
    "                    scheduler.step()\n",
    "\n",
    "                epoch_loss = running_loss / self.dataset_sizes[phase]\n",
    "                epoch_acc = running_corrects.double() / self.dataset_sizes[phase]\n",
    "                \n",
    "                # Add ClearML Graphs\n",
    "                if self.logger != None:\n",
    "                    self.logger.report_scalar(\"Loss\", f\"Stage {self.stage + 1}: {phase}\", iteration=(epoch), value=epoch_loss)\n",
    "                    self.logger.report_scalar(\"Accuracy\", f\"Stage {self.stage + 1}: {phase}\", iteration=(epoch), value=epoch_acc)\n",
    "\n",
    "                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print(f'Training stage completed in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "\n",
    "        return model\n",
    "\n",
    "\n",
    "    def model_setup(self, model_ft):\n",
    "        num_ftrs = model_ft.classifier[1].in_features\n",
    "        # Here the size of each output sample is set to 2.\n",
    "        # Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, len(self.class_names))\n",
    "        return model_ft\n",
    "\n",
    "    def train_model_setup(self, model):\n",
    "        model_ft = model\n",
    "\n",
    "        model_ft = model_ft.to(self.device)\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        # Observe that all parameters are being optimized\n",
    "        optimizer_ft = optim.RMSprop(model_ft.parameters(), lr=self.general_params[\"learning_rate\"], momentum=self.general_params[\"momentum\"]) #, weight_decay=self.general_params[\"weight_decay\"])\n",
    "\n",
    "\n",
    "        exp_lr_scheduler = lr_scheduler.ExponentialLR(optimizer_ft, gamma=self.general_params[\"learning_rate_decay\"])\n",
    "\n",
    "        model_ft = self.train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=self.stage_params[\"epochs\"])\n",
    "        return model_ft\n",
    "\n",
    "\n",
    "    def run_stage_manager(self):\n",
    "        print(\"Starting training\")\n",
    "        \n",
    "        if not os.path.isdir(\"Training\"):\n",
    "            os.makedirs(\"Training\")\n",
    "        \n",
    "        for self.stage in range(0, self.general_params.get(\"stages\", 4)):\n",
    "            print(f\"Starting stage {self.stage + 1}\")\n",
    "            self.stage_params_func(self.stage_params, self.general_params.get(\"stages\", 4))\n",
    "            self.data_loader()\n",
    "\n",
    "            if self.stage == 0:\n",
    "                model = torchvision.models.get_model(self.general_params[\"model\"], dropout=self.params[\"dropout\"])\n",
    "                model = self.model_setup(model)\n",
    "                model = self.train_model_setup(model)\n",
    "                torch.save(model.state_dict(), f'Training/model_weights_stage{self.stage}.pth') #save the current weights to file\n",
    "            else:\n",
    "                model = torchvision.models.get_model(self.general_params[\"model\"], dropout=self.params[\"dropout\"])\n",
    "                model = self.model_setup(model)\n",
    "                model.load_state_dict(torch.load(f'Training/model_weights_stage{self.stage-1}.pth')) # load the weights of the previous stage into the currenct network which has a different dropout value\n",
    "                model = self.train_model_setup(model)\n",
    "                torch.save(model.state_dict(), f'Training/model_weights_stage{self.stage}.pth')\n",
    "                \n",
    "            del model, self.dataloaders\n",
    "            torch.cuda.empty_cache() # Clearing the GPU memory for the next stage\n",
    "            print(f\"Finished stage {self.stage}\\n\\n\\n\")\n",
    "            time.sleep(5)\n",
    " \n",
    "        print(\"Finished all stages\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bedd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "ClearML = False\n",
    "if ClearML:\n",
    "    # ClearML setup\n",
    "    from clearml import Task, Logger\n",
    "    %env CLEARML_WEB_HOST=https://app.clear.ml\n",
    "    %env CLEARML_API_HOST=https://api.clear.ml\n",
    "    %env CLEARML_FILES_HOST=https://files.clear.ml\n",
    "    # Pytorch\n",
    "    %env CLEARML_API_ACCESS_KEY=API_KEY\n",
    "    %env CLEARML_API_SECRET_KEY=API_SECRET\n",
    "\n",
    "    task = Task.init(project_name='ImageNetTE', task_name='ImageNetTE - EfficientNetV2-S')\n",
    "\n",
    "    task.set_base_docker(docker_image=\"nvcr.io/nvidia/pytorch:23.03-py3\", docker_arguments=\"--rm -e LOCAL_PYTHON=/usr/bin/python3 --ipc=host\")\n",
    "    logger = task.logger\n",
    "else:\n",
    "    logger = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a495c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ClearML hyper parameters\n",
    "general_params = {\n",
    "    \"model\": \"efficientnet_v2_s\",\n",
    "    \"batch_size\": 1,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"learning_rate_decay\": 0.99,\n",
    "    \"momentum\": 0.9,\n",
    "    #\"weight_decay\": 0,\n",
    "    \"stages\" : 4,\n",
    "}\n",
    "if ClearML: general_params = task.connect(general_params, name=\"general\")  # enabling configuration override by clearml\n",
    "\n",
    "stage_params = {\n",
    "    \"image_size_min\": 128,\n",
    "    \"image_size_max\": 300,\n",
    "    \"dropout_min\": 0.1,\n",
    "    \"dropout_max\": 0.3,\n",
    "    \"randaug_magnitude_min\": 5,\n",
    "    \"randaug_magnitude_max\": 15,\n",
    "    \"epochs\": 1,\n",
    "}\n",
    "if ClearML: stage_params = task.connect(stage_params, name=\"Stage Params\")  # enabling configuration override by clearml\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd3d45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_stages(general_params=general_params, stage_params=stage_params, logger=logger)\n",
    "start = time.time()\n",
    "train.run_stage_manager()\n",
    "print(f\"Finished training in {(time.time() - start) / 60} minutes\")\n",
    "task.logger.report_single_value(\"Training Time, minutes\", (time.time()-start) / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da160cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ClearML: task.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
